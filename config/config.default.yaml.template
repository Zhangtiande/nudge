# Nudge Configuration File
#
# This is the default configuration template for Nudge.
# Documentation: https://github.com/Zhangtiande/nudge
#
# Configuration file locations:
#   Linux:   ~/.config/nudge/config.yaml
#   macOS:   ~/Library/Application Support/nudge/config.yaml
#   Windows: %APPDATA%\nudge\config.yaml

# ========================================
# LLM Model Configuration
# ========================================
model:
  # API endpoint URL
  # Default uses local Ollama server. For OpenAI, use: https://api.openai.com/v1
  # For other OpenAI-compatible APIs, replace with your endpoint
  endpoint: "http://localhost:11434/v1"

  # Model name to use for completion
  # For Ollama: "codellama:7b", "deepseek-coder:6.7b", etc.
  # For OpenAI: "gpt-4", "gpt-3.5-turbo", etc.
  model_name: "codellama:7b"

  # API key (direct configuration, takes precedence over api_key_env)
  # You can directly specify your API key here for quick setup
  # Note: Using api_key_env is recommended for better security
  # api_key: "sk-your-api-key-here"

  # Environment variable name containing API key (fallback if api_key is not set)
  # Uncomment and set this if your LLM requires authentication
  # For OpenAI: api_key_env: "OPENAI_API_KEY"
  # For other providers: api_key_env: "YOUR_API_KEY_ENV_VAR"
  # api_key_env: "OPENAI_API_KEY"

  # Request timeout in milliseconds
  # Increase this if you get timeout errors with slower models
  timeout_ms: 5000

# ========================================
# Context Configuration
# ========================================
context:
  # Number of recent shell history entries to include
  # Larger values provide more context but use more tokens
  history_window: 20

  # Include current directory file listing in context
  # Helps LLM understand available files and directories
  include_cwd_listing: true

  # Include exit code of last command
  # Helps LLM understand if previous command succeeded or failed
  include_exit_code: true

  # Include system information (OS, architecture, shell type, etc.)
  # Helps LLM provide platform-specific suggestions
  include_system_info: true

  # Enable similar commands search from history
  # Finds and includes commands similar to current input
  similar_commands_enabled: true

  # Number of history commands to search for similar commands
  # Larger values search deeper but may be slower
  similar_commands_window: 200

  # Maximum number of similar commands to return
  # Prevents context overflow with too many matches
  similar_commands_max: 5

  # Maximum number of files to include in directory listing
  # Prevents token overflow in large directories
  max_files_in_listing: 50

  # Maximum total tokens for all context
  # Context is automatically truncated based on priorities below
  max_total_tokens: 4000

  # Priority for each context type (higher = more important)
  # When truncating context, lower priority items are removed first
  priorities:
    history: 80         # Shell command history
    cwd_listing: 60     # Current directory listing
    plugins: 40         # Plugin output (e.g., git status)

# ========================================
# Plugins Configuration
# ========================================
plugins:
  git:
    # Enable Git plugin to include repository context
    enabled: true

    # Detail level: light, standard, or detailed
    # - light:    branch name, clean/dirty status
    # - standard: + staged/unstaged files
    # - detailed: + recent commits
    depth: standard

    # Number of recent commits to include (only in detailed mode)
    recent_commits: 5

  docker:
    # Enable Docker plugin to include container/image context
    enabled: true

    # Timeout for Docker command execution (milliseconds)
    timeout_ms: 100

    # Plugin priority for truncation (1-100, higher = kept longer)
    # priority: 45

    # Maximum containers to include in context
    max_containers: 10

    # Maximum images to include in context
    max_images: 10

    # Show running containers in context
    show_containers: true

    # Include docker-compose service information
    include_compose: true

    # Include Dockerfile preview (first 50 lines)
    include_dockerfile: true

  node:
    # Enable Node.js plugin to include project context
    enabled: true

    # Timeout for file operations (milliseconds)
    timeout_ms: 100

    # Plugin priority for truncation (1-100, higher = kept longer)
    # priority: 45

    # Maximum dependencies to include in context
    max_dependencies: 50

  rust:
    # Enable Rust plugin to include Cargo project context
    enabled: true

    # Timeout for file operations (milliseconds)
    timeout_ms: 100

    # Plugin priority for truncation (1-100, higher = kept longer)
    # priority: 45

    # Maximum dependencies to include in context
    max_dependencies: 50

  python:
    # Enable Python plugin to include project context (uv, poetry, pip)
    enabled: true

    # Timeout for file operations (milliseconds)
    timeout_ms: 100

    # Plugin priority for truncation (1-100, higher = kept longer)
    # priority: 45

    # Maximum dependencies to include in context
    max_dependencies: 50

# ========================================
# Trigger Configuration
# ========================================
trigger:
  # Trigger mode: manual or auto
  # - manual: Only trigger when hotkey is pressed
  # - auto:   Trigger automatically on certain conditions
  mode: manual

  # Hotkey binding (readline format)
  # Default: Ctrl+E
  # Other examples: "\\C-g" (Ctrl+G), "\\C-x\\C-a" (Ctrl+X Ctrl+A)
  hotkey: "\\C-e"

  # Auto mode debounce delay in milliseconds
  auto_delay_ms: 500

  # Zsh ghost text owner strategy
  # - auto:            Prefer zsh-autosuggestions if available, otherwise nudge
  # - nudge:           Force nudge to render ghost text
  # - autosuggestions: Reserve ghost text for zsh-autosuggestions
  zsh_ghost_owner: auto

  # Zsh overlay rendering backend
  # - message: Render overlay with `zle -M` (default, less prompt redraw)
  # - rprompt: Render overlay in right prompt (`RPS1`)
  zsh_overlay_backend: message

# ========================================
# Cache Configuration
# ========================================
cache:
  # Max cache entries (LRU)
  capacity: 1024

  # Max bytes of prefix used for key hashing
  prefix_bytes: 80

  # TTL for auto mode (milliseconds) - 5 minutes
  # Cache key includes: prefix + cwd + git_state + shell_mode
  # Context changes (git status, directory) automatically invalidate cache
  ttl_auto_ms: 300000

  # TTL for manual/inline modes (milliseconds) - 10 minutes
  ttl_manual_ms: 600000

  # TTL for negative cache entries (milliseconds) - 30 seconds
  ttl_negative_ms: 30000

  # Stale-while-revalidate threshold (0.0 - 1.0)
  stale_ratio: 0.8

# ========================================
# Privacy & Safety Configuration
# ========================================
privacy:
  # Enable automatic sanitization of sensitive data
  # Removes API keys, passwords, tokens from context before sending to LLM
  sanitize_enabled: true

  # Custom regex patterns to sanitize (in addition to built-in patterns)
  # Example: ["MY_SECRET_.*=.*", "password:\\s*\\S+"]
  custom_patterns: []

  # Block dangerous commands from being suggested
  # Built-in rules detect: rm -rf, fork bombs, system destruction, etc.
  block_dangerous: true

  # Custom dangerous command patterns to block
  # Example: ["shutdown.*", "reboot.*"]
  custom_blocked: []

# ========================================
# Logging Configuration
# ========================================
log:
  # Log level: trace, debug, info, warn, error
  # - trace/debug: Very verbose, for troubleshooting
  # - info:        Normal operation messages
  # - warn/error:  Only problems
  level: "info"

  # Enable file logging with daily rotation
  # Logs are written to:
  #   Linux/macOS: ~/.config/nudge/logs/ or ~/Library/Application Support/nudge/logs/
  #   Windows:     %APPDATA%\nudge\logs\
  file_enabled: false

# ========================================
# Error Diagnosis Configuration
# ========================================
diagnosis:
  # Enable automatic error diagnosis and fix suggestions
  # When enabled, Nudge will analyze failed commands and suggest fixes
  # WARNING (Zsh): stderr is temporarily redirected during command execution
  #   - Error messages won't display in real-time
  #   - After failure, Nudge shows captured errors with diagnosis
  # Default: false (must opt-in)
  enabled: false

  # Zsh: Capture stderr to temporary file for analysis
  # Disable if you experience issues with certain programs
  capture_stderr: true

  # Zsh: Show suggested fix as gray inline text (Tab to accept)
  # Uses the same mechanism as auto-mode suggestions
  auto_suggest: true

  # Maximum stderr size to send to LLM (bytes)
  # Larger errors are truncated to prevent token overflow
  max_stderr_size: 4096

  # Timeout for diagnosis request (milliseconds)
  timeout_ms: 5000

  # Interactive commands that should skip stderr capture
  # These programs need real-time stderr output and user interaction
  # The shell integration checks the first word of the command against this list
  # You can add custom commands in your config.yaml to extend this list
  interactive_commands:
    # Editors
    - vim
    - nvim
    - vi
    - nano
    - emacs
    - code
    # Remote access
    - ssh
    - telnet
    - mosh
    # Interactive tools
    - top
    - htop
    - btop
    - less
    - more
    - man
    # Fuzzy finders
    - fzf
    - sk
    # Terminal multiplexers
    - tmux
    - screen
    # Interactive shells/REPLs
    - python
    - python3
    - ipython
    - node
    - irb
    - psql
    - mysql
    - sqlite3
    # Other interactive programs
    - watch
    - tail

# ========================================
# Advanced Configuration
# ========================================

# Custom system prompt (optional)
# Override the default system prompt sent to the LLM
# Use this to customize the AI's behavior and response style
# system_prompt: |
#   You are a helpful command-line assistant.
#   Suggest commands that are safe, efficient, and follow best practices.
#   Always explain what the command does if it's complex.
